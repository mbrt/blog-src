#+TITLE: Antifurto: home-made security camera
# to get rid of the '_' subscript problem
#+OPTIONS: ^:{}

* Introduction
In February 2014 I had a very unpleasant surprise after coming back home from a
weekend in Berlin. Me and my girlfriend found out our apartment upside down
because of burglars. We suffered the loss not only of many of our belongings,
but worse, of our safety. We didn't feel safe in our home and we didn't feel
safe to leave it - not even for half an hour - for the fear to come back and
find somebody inside. It was with this mood that I started this project: totally
motivated to do something about it.

My goal was to install in the apartment a security alarm that was cheap, safe
and easy to use. Nowadays there are plenty of alternatives that satisfy all the
requirements, but at that moment I couldn't find anything like that. As I'm a
software engineer, I decided to jump into the project and spend most of my free
time on it (my girlfriend was only partially happy with that).

The end result was a Raspberry Pi with a camera module and a bunch of software,
in part taken from the open-source and in part written by me. As of the time of
writing, it's been running in production (namely my apartment) untouched for
more than two years now. Ironically my security camera lasted way more than my
apartment, because since then I moved twice already. So, quite a success for me.

And, if you're asking yourself if I had any burglars again since then, the
answer is no, luckily. But I had the opportunity to test it multiple times when
my parents intruded my apartment without permission...

** Why?
At this point you can probably see my motivation behind the project, and also
the target audience: I needed something cheap that I, and my girlfriend could
use. This set of users was important for the design. It meant that the normal
usage should be simple, because my girlfriend (who is not a developer) had to
use it. The configuration and maintenance was however on me, so I didn't focus
on make that simple.

Today I'm open-sourcing the project. You can find it on GitHub under
[[https://github.com/mbrt/antifurto][mbrt/antifurto]]. The name comes from an Italian word that means "security alarm".
As I'm very lazy in finding names, the codename with which I started the project
has remained till now.

Why am I open-sourcing that now, and not before? Why not keeping it closed
source? The project started to meet my needs, so I had no reason at the
beginning to open source something that was completely tied to my use case.
Nobody would have gotten any particular benefit from it. After some time however
it grown up into a more featured product. So, since at the time I wasn't happy
with my job, I considered starting a business and commercialize it. Long story
short, getting funds for startups in Italy is quite hard, so I needed money from
myself or my family. I then had to improve many parts of the project because I
needed to scale out for multiple customers. It was not only about my apartment
anymore. In the meantime competitors started to jump out from nowhere before I
even got started. I had an opportunity for a new job, so my motivations fell
apart very rapidly.

At the end of the day, there is not a commercial product, but a working
prototype, and an interesting experience to share. I decided to open-source it
now, because I needed time to put together this writeup and cleanup some
documentation. All boring things for me, so it took me quite some time.

** What?
In this writeup I'm going to present the interesting bits of the project. I will
try to not focus too much on the details, but rather to present clearly the
high-level architecture, some design decisions and some interesting
implementation bits.

** Features
The antifurto project is essentially a security camera that allows to monitor
what happens through the lenses of a single camera. When the camera detects
motion above a certain threshold, it sends notifications through WhatsApp and
e-mail and starts to record pictures. These are in turn saved to the local disk
and uploaded to a Dropbox folder. There is also a web portal from which you can
start and stop the monitoring, a live view from which you can see images in real
time and an archive page for the past recordings. It's not possible to combine
multiple cameras together.

* Architecture
The project architecture is simple. Everything lives inside a Raspberry Pi,
period. There isn't a server component communicating with the camera, or
anything else. This is not an ideal architecture from the security point of
view, because all the keys, including SSL, Dropbox API secrets, e-mail
passwords, etc are inside that box. It was the perfect solution for me, because
instead of a device and a server to manage, I had only one device. Moreover, the
development time was reduced because the architecture was simpler.

This unfortunately cannot work out if you want to provide the project to your
mother (assuming she's not a software developer). The Raspberry needs a non-zero
amount of maintenance, to provide a minimum amount of security. This includes
for example installing OS updates and rebooting the device periodically. The
keys need to be safe guarded inside the Raspberry itself, and re-generated in
case of leak. Again, this is not good if you want to do it properly, but I
preferred to do something quick and get it working as fast as I could.

Now for the details. The project is divided into three main parts:
+ the main =antifurto= executable (written in C++), which is responsible for the
  monitoring and notifications;
+ a web server (Apache + PHP), that serves the website from which you can see
  the images live, turn the monitoring on and off and view the archive;
+ a FastCGI component that serves as a bridge between lighttpd and the main
  executable.

There are also other small satellite components and scripts, such as:
+ a bash script to send emails with =mail=;
+ python scripts to send WhatsApp notifications and upload pictures to Dropbox.

You can see below a diagram of the high level architecture:

[[file:overview.svg]]

As you can see, the pictures come from the camera module, and are processed by
the =antifurto= main executable. This decides whether to store the pictures on
the local hard drive (an SD card), and upload them on Dropbox or not. It also
decides, when to send notifications via e-mail or WhatsApp messages. Whenever
from the web interface, the user decides to start a live view, or control the
monitoring start and stop, it sends a POSIX signal to the main process. This
will in turn start sending the pictures over the =zmq= channel to the
=antifurto.fcgi= component. Its only task is to forward them to the webserver
via a fast FCGI socket.

The design is heavily based on [[https://en.wikipedia.org/wiki/Observer_pattern][observers]], [[https://en.wikipedia.org/wiki/Type_erasure][type erasure]] and the [[https://en.wikipedia.org/wiki/Composition_over_inheritance][composite reuse
principle]], to minimize dependencies among components. Well, at least I tried to
keep those in mind.

* Main executable
In this long section I'm going to talk about the internal details of the main
executable, called =antifurto=, for a very lack of fantasy.

** Main class
The main class is called ~Antifurto~, what a surprise! It is responsible to
start and stop the monitoring and the live view, by orchestrating the resources
involved. It uses a ~Config~ structure for the configuration, that comes from
the command line and the configuration file. It can be used as an external
library, as most of the components in this project, since it is self contained.

It contains all the controllers, that are described in the [[Main controllers]]
section, and the implementation details are hidden from the header file behind a
[[https://herbsutter.com/gotw/_100/][Pimpl]].

The interface is very simple: it takes a configuration and the user can control
when to start and stop monitoring and live view from four public methods:

#+BEGIN_SRC c++
  class Antifurto
  {
  public:
    Antifurto(const Configuration& c, bool maintenanceNeeded = true);

    void startMonitoring();
    void stopMonitoring();

    void startLiveView();
    void stopLiveView();

  private:
    meta::ErasedUniquePtr<AntifurtoImpl> pimpl_;
  };
#+END_SRC

So, this class is all about the very high level use cases of configuring,
starting and stopping the main functionalities.[fn:1]

These functions are a bit less simple than one can at first imagine. For example
the ~startMonitoring~ is anynchronous and starts the monitoring only after a
configurable timeout. This is because after the start, the user may need to get
out the way before the monitoring effectively starts. The default I'm using for
myself is one minute. At the same time, the function needs to check if the user
cancels the start request before the timer goes off. I needed to put some
attention in the interaction between start, stop and the destructor. The camera
controller (see the [[CameraController]] section for an overview) lifetime depends
on whether one between the monitoring and the live view functionalities are on:

#+BEGIN_SRC c++
  void handleCameraControllerNeed()
  {
    if ((liveViewActive_ || monitorActive_) && !camera_)
      camera_.reset(new CameraController());
    else if (!liveViewActive_ && !monitorActive_)
      camera_.reset();
  }
#+END_SRC

This method is by all the four external methods, to factor out this common part.

** Main controllers
In this section I'm going to describe the three controllers that manage the
monitoring, live view and the camera sub-components.

*** MonitorController
This class controls the monitoring functionality life cycle. It delegates to its
sub-components tasks such as motion detection, and notifications. The most
important part of its public interface is the ~examinePicture~ function:

#+BEGIN_SRC c++
  void examinePicture(const Picture& picture);
#+END_SRC

The [[Main class]] calls this function whenever a new picture comes out of the
camera.

Another interesting bit is the way this class asks for the upper level
controller to change the picture capture interval, or to stop the recording
altogether. To break cyclical dependencies, the upper level class has to
instantiate the ~MonitorController~ by passing a couple of callbacks. One of
them is the ~SetPicturesInterval~:

#+BEGIN_SRC c++
  using SetPicturesInterval = std::function<void(std::chrono::milliseconds)>;
#+END_SRC

that is used whenever some motion is detected. In that case, the
~MonitorController~ asks for an increase of the capture frequency. It's also
useful whenever nothing is going on, to decrease it and so save energy:

#+BEGIN_SRC c++
  void MonitorController::onAlarmStateChanged(MotionDetector::State state)
  {
    using State = MotionDetector::State;

    switch (state) {
    case State::NO_ALARM:
      setPicturesInterval_(config::monitorCycleDuration());
      break;
    case State::PRE_ALARM:
      setPicturesInterval_(config::monitorCycleDurationOnAlarm());
      break;
    default:
      break;
    }
    log::info() << "Alarm state: " << state;
  }
#+END_SRC

*** CameraController
This class is responsible to take pictures from a camera at a given rate. An
user of this class can register an observer and specify the rate at which the
pictures have to be taken:

#+BEGIN_SRC c++
  class CameraController
  {
  public:
    using Subject = meta::Subject<const Picture&>;
    using Observer = Subject::Observer;
    using Registration = Subject::Registration;
    using Period = std::chrono::milliseconds;

    /// Set the pictures capture rate
    void setDesiredPeriod(Registration const& r, Period period);

    /// Add an observer to the pictures flow
    Registration addObserver(Observer observer, Period desiredPeriod);

    // ...
  };
#+END_SRC

This uses the observer pattern, implemented as an utility in the [[meta namespace.]]

Every time a picture is taken, the observer callback is called. If multiple
observers are interested in different capture rates, the maximum rate is used.
This means that an observer specifies the minimum speed, but it could get
pictures at a higher speed also, if others require that.

To implement this functionality, in a separate thread a ~Metronome~ class sleeps
the required time, and then the ~Camera~ class takes a picture. Every time an
observer is registered or de-registered, the sleep time is updated.

*** LiveViewController
This class starts and stops the live view functionality. It doesn't implement
the functionality itself; it just controls the lifetime of a [[LiveView]] object.
From the outside it takes pictures and start and stop commands.

Whenever a picture comes, it is forwarded to the internal ~LiveView~ object. To
detect when the user is not interested in the live view anymore, I've built a
primitive control flow, that is basically a buffer of pictures that are sent to
the browser. When the client doesn't request them, the buffer fills up. After a
certain timeout, the ~LiveViewController~ simply stops the live view:

#+BEGIN_SRC c++
  if (liveView_->addPicture(p))
      lastPictureWrittenTime_ = system_clock::now();
  else if (system_clock::now() - lastPictureWrittenTime_ > timeout_)
      stop();
#+END_SRC

To do this, the internal ~LiveView~ object simply informs whether it has been
able to process the image or not, and if not, the timeout is checked.

The ~stop~ function invokes a callback, that asks to be de-registered from the
stream of pictures.

** Picture's capture
*** MotionDetector
This class uses the [[http://opencv.org/][OpenCV]] library to examine the pictures flow and determines
when something is moving. It implements the observer pattern to notify the
observers for the current state. The motion detection code is pretty simple:

#+BEGIN_SRC c++
  cv::absdiff(curr_, p, currDiff_);
  cv::bitwise_and(prevDiff_, currDiff_, motion_);
  if (motionHappened())
      onMotionDetected();
  else
      onNoMotion();
  // save
  std::swap(prevDiff_, currDiff_);
  curr_ = p;
#+END_SRC

The code works with three pictures: the current one and the two previous. Two
images are computed out of them by making a difference (i.e. subtracting the
gray values of the pixels one by one) between the first with the second and the
second with the third. Then a bitwise and is computed between them. Random noise
will be filtered out, since it's unlikely to stay still for three frames, and
the image will be almost completely black. Whenever something moves however,
certain areas of the pictures will differ among the three frames, and so the
difference will produce white pixels. These pixels are then counted in
~motionHappened()~, and if they exceed a certain threshold, then motion is
detected.

There is an additional layer of protection against errors, and it's a state
machine that counts how many consecutive moving pictures have been detected.
These states are used to better control:
+ energy saving
+ picture capturing
+ alarm notifications

[[file:motion-detector.svg]]

Every time a transition occurs in this state machine, all the observers are
notified. It will be up to them to take the right action.

Everything starts from the =IDLE= state. Whenever some motion is detected, the
state becomes =PRE_ALARM=. If no mor motion frames are detected, the state goes
back to =IDLE=. If the motion continues however, the state machine transitions
to =ALARM=. It stays there while the motion continues. When it stops, the state
goes to the =STILL= state. This means that even though nothing is moving, for
some time, the alert level is still on alarm. Indeed, if some motion happens
again, the state turns immediately to =ALARM= again. If instead nothing happens
for some time, the state goes back to =IDLE=.

In this way we have decoupled the abstract states in which the system may be
with the actions the various components have to take to respond.

*** Camera
The camera type is statically determined in =StaticConfig.hpp=. In the
Raspberry-Pi case, there is a homegrown version implemented by ~PiCamera~ that
uses a slightly modified version of the =picam= library, that I found [[http://robotblogging.blogspot.nl/2013/10/an-efficient-and-simple-c-api-for.html][here]]. This
library is a simple interface on top of the Raspberry [[https://github.com/mbrt/userland][userland]] library I forked
just to ease the build. To capture images outside the Raspberry world I instead
opted for the [[http://opencv.org/][OpenCV]] library and implemented ~CvCamera~. Now, I have to admit
that the ~CvCaptureRAII~ class might look a bit weird, but it was an attempt to
implement the camera resource through [[https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization][RAII]]. I took inspiration from Martinho
Fernandez [[https://rmf.io/cxx11/rule-of-zero][rule of zero]] blog post and the [[http://scottmeyers.blogspot.nl/2014/03/a-concern-about-rule-of-zero.html][concern about the rule of zero]] by Scott
Meyers. To discuss this in detail I would need an entire blog post in itself, so
I'll just point you to these valuable resources. To be honest I'm not very
satisfied by its look and feel now.

With the same spirit I implemented the capture resource for ~PiCamera~, which is
just a one liner:

#+BEGIN_SRC c++
  std::unique_ptr<CCamera, void(*)(CCamera*)> capture_;
#+END_SRC

It uses the non-so-well-known custom deleter feature of ~std::unique_ptr~.
Again, look at Fernandez post for an explanation on why I didn't just
implemented a stupid destructor for ~PiCamera~. Everything is handled
automatically, since in the constructor I pass the resource, and the deleter
function to be called in destruction (namely ~picam_stop_camera~):

#+BEGIN_SRC c++
  PiCamera::PiCamera(int width, int height)
    : width_(width), height_(height)
    , capture_(::picam_start_camera(width, height, 10, 1, false),
               &::picam_stop_camera)
  {
    // ...
  }
#+END_SRC

These two different implementations of the camera resource were not intended to
be used at the same time: one was only for the Raspberry Pi hardware, and the
other for PC's with USB cameras. For this reason I didn't introduce any common
interface, and just used a compile time define and a ~typedef~ to switch between
them:

#+BEGIN_SRC c++
  namespace antifurto {
  namespace config {

  #if defined(ANTIFURTO_RASPBERRY)
      using Camera = antifurto::PiCamera;
  #else
      using Camera = antifurto::CvCamera;
  #endif

  }}
#+END_SRC

The code will simply refer to the ~antifurto::config::Camera~ type to get a
capture resource. I just needed to make sure their public interface (i.e. the
public methods) are the same, so the two classes could be used interchangeably.

This trick is quite handy if you don't need runtime polymorphism, but honestly
it's a bit overkill for this project.

** LiveView
** Picture recording
*** RecordingController
This class is responsible for managing the registration of the pictures while an
alarm is active. It accepts pictures with ~void addPicture(Picture p)~ and
registers itself to the [[MotionDetector]] to know when to start and stop the
recording. This is done by saving jpeg pictures on the local file system (by
using [[PictureArchive]]) and uploading them to Dropbox (by using [[DropboxUploader]]).

The state machine is quite simple:

#+BEGIN_SRC c++
  void RecordingController::onAlarmStateChanged(MotionDetector::State state)
  {
      using State = MotionDetector::State;
      switch (state) {
      case State::NO_MOTION:
          archive_.stopSaving();
          break;
      case State::NO_ALARM:
          enqueueOlderPictures();
          break;
      case State::ALARM:
          archive_.startSaving();
          break;
      case State::PRE_ALARM:
      default:
          break;
      }
  }
#+END_SRC

Whenever the motion detector notifies this class about an alarm, it starts to
save the pictures. When there is no motion involved (even if the alarm is still
active), the recording is stopped.

Saving pictures in real time is important, both on the disk and online. If there
is a slow upload for any reason, the queue between the producer (the [[Camera]]) and
the consumer (the uploader), grows. This would mean that by looking at the
pictures online, the delay between capture and upload will grow more and more
over time during alarms. To avoid this behavior, the queue size is limited, and
whenever it's full, the coming pictures are queued in a secondary one:

#+BEGIN_SRC c++
  void RecordingController::onPictureSaved(const std::string& fileName)
  {
      if (!uploadWorker_.enqueue(fileName)) {
          log::info() << "Failed to upload picture to Dropbox: queue is full";
          std::unique_lock<std::mutex> lock(toUploadAfterQueueMutex_);
          toUploadAfterQueue_.emplace(fileName);
      }
  }
#+END_SRC

This ensures a fixed maximum delay between capture and upload, just by skipping
pictures now and then, when the queue is full. All the missing pictures are
instead uploaded when the alarm is not active anymore (the ~case
State::NO_ALARM:~ above):

#+BEGIN_SRC c++
  while (!toUploadAfterQueue_.empty()) {
      if (uploadWorker_.enqueue(toUploadAfterQueue_.front()))
          toUploadAfterQueue_.pop();
      else
          break;
  }
  // if the queue is not empty, we need to schedule another upload cycle
  if (!toUploadAfterQueue_.empty()) {
      log::info() << "Cannot empty the upload queue. Schedule a new upload";
      scheduler_.scheduleAfter(std::chrono::minutes(10), [this] {
            enqueueOlderPictures();
      });
   }
#+END_SRC

The logic is a bit brutal but it works. While there is still something to
upload, it adds the pictures to the upload queue. If the queue gets full again,
a new procedure is scheduled after 10 minutes.

There is another maintenance procedure, to avoid a full hard drive. Every 24
hours, older pictures are removed. Depending on the configuration, only a
certain amount of days are kept:

#+BEGIN_SRC c++
  // schedule maintenance at every midnight
  using namespace std::chrono;
  auto maintenanceWork = [this] { performMaintenance(); };
  scheduler_.scheduleAt(concurrency::tomorrow() + minutes(1), [=] {
      performMaintenance();
      scheduler_.scheduleEvery(hours(24), maintenanceWork);
  });
#+END_SRC

*** PictureArchive
This class saves pictures in Jpeg format to a given folder. It takes a stream of
pictures and two commands: ~startSaving~ and ~stopSaving~. When the recording is
started, not only the next picture is saved, but also some of the previous. This
object has indeed a fixed sized circular buffer that allows to retroactively
save the images right before an alarm popped up. It also allows observers to
register for when a picture is saved to disk, getting the file name.

This is the function that saves the pictures:

#+BEGIN_SRC c++
  void PictureArchive::save(Picture& p, Clock t)
  {
      std::string filename{ fs::concatPaths(currentFolder_,
          text::toString(t, text::ToStringFormat::FULL, '-', '_') + ".jpg")};

      cv::putText(p, text::toString(t, text::ToStringFormat::SHORT, '/', ' '),
                  cv::Point(30,30), CV_FONT_HERSHEY_COMPLEX_SMALL, 0.8,
                  cv::Scalar(200,200,250), 1, CV_AA);
      cv::imwrite(filename, p, {CV_IMWRITE_JPEG_QUALITY, 90});
      notifyObservers(filename);
  }
#+END_SRC

The picture gets an overlapping timestamp on the top left corner and then are
saved on the disk with the timestamp in the filename.

On the bad side is the ring buffer, which is actually not a ring buffer at all.
Pictures are pushed to the end of a vector. The beginning is then deleted by
moving all the other elements at the previous index. Not pretty, not fast, but
all in all it works. Moving to a proper circular buffer it's not very hard but I
didn't feel like it because this wasn't a bottleneck.

*** TODO DropboxUploader
This class is responsible for uploading files to a Dropbox account, by using an
external =dropbox_uploader.sh= script. It just generates a configure file for
it, starting from the Antifurto's configuration, and uploads a file when
requested, by launching an external process.

*Talk about the external script*

** Notifications
** Utility libraries
*** meta namespace

* Footnotes
[fn:1]
If you are curious, the ~ErasedUniquePtr~ class is briefly described in the [[meta
namespace]] section.
